{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling and Feature Engineering Exercise\n",
    "\n",
    "Place your answers within the code blocks that have the comment.\n",
    "\n",
    "```python\n",
    "# your code here\n",
    "```\n",
    "\n",
    "Make sure to remove or comment the line below to be able to proceed. It's only placed there as a reminder that the function has not yet been implemented.\n",
    "\n",
    "```python\n",
    "raise NotImplementedError\n",
    "```\n",
    "\n",
    "## Note on \"test scripts\"\n",
    "\n",
    "The code bloock following the function definition are \"unit tests\" which are code blocks which test if the function you implemented is correct or not. It will not print an output **if the conditions are met** (meaning the answer is correct)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boston Dataset\n",
    "\n",
    "We will be using the boston house pricing dataset for exercises 1-5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "data_bunch = load_boston()\n",
    "data = data_bunch['data']\n",
    "feature_names = data_bunch['feature_names']\n",
    "descr = data_bunch['DESCR']\n",
    "\n",
    "df = pd.DataFrame(data, columns=feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(descr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.** Change the data type of `CHAS` column to **int** and apply one-hot encoding using `pandas`. **(2 pts.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "df1[\"CHAS\"] = df1[\"CHAS\"].astype(int)\n",
    "df1_onehot = pd.get_dummies(df1, columns=[\"CHAS\"])\n",
    "df1_onehot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_onehot.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_onehot['CHAS_0'].values[150:170].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_onehot['CHAS_1'].values[150:170].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert df1.columns.tolist()==['CRIM', 'ZN', 'INDUS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', \n",
    "                              'TAX', 'PTRATIO', 'B', 'LSTAT', 'CHAS_0', 'CHAS_1']\n",
    "assert df1['CHAS_0'].values[150:170].tolist()==[1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1]\n",
    "assert df1['CHAS_1'].values[150:170].tolist()==[0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2.** Filter out the entries wherein the crime rate is lower than the mean. **(2 pts.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "df2_crim = df2[df2[\"CRIM\"] < df2[\"CRIM\"].mean()] #lower than the mean, the assert is a result of higher than the mean\n",
    "df2_crim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_crim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_crim.values[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert df2.shape==(128, 13)\n",
    "assert df2.values[0].tolist()==[4.0974, 0.0, 19.58, 0.0, 0.871, 5.468, 100.0, 1.4118, 5.0, 403.0, 14.7, 396.9, 26.42]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.** Change the values of `RAD` column based on the following rules: **(4 pts.)**\n",
    " - if 1 to 4, change it to 1.\n",
    " - if 5 to 8, change it to 2.\n",
    " - otherwise, change it to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.copy()\n",
    "df3.loc[(df[\"RAD\"] >= 1) & (df[\"RAD\"] <= 4), \"RAD\"]  = 1\n",
    "df3.loc[(df[\"RAD\"] >= 5) & (df[\"RAD\"] <= 8), \"RAD\"]  = 2\n",
    "df3.loc[(df[\"RAD\"] > 8) | (df[\"RAD\"] < 0), \"RAD\"]  = 3\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['RAD'].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert df3['RAD'].value_counts().to_dict()=={1: 192, 2: 182, 3: 132}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4.** Using the dataframe output from exercise 3, group the entries based on `RAD` column, and get the mean of crime rates for each group. You should end up with a `Series` data structure. Please refer to the assert to have an idea of what is expected. **(2 pts.)**\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.copy()\n",
    "df4.groupby(\"RAD\")[\"CRIM\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert df4.to_dict()=={1: 0.2591065625, 2: 0.5190552747252744, 3: 12.759290909090915}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5.** Using the dataframe output from exercise 3, group the entries based on `RAD` column, and get the following statistics: count, mean, std, min, 25%, 50%, 75%, and max crime rates for each group. Have all those statistics as column names for the columns of the new `DataFrame`. This means your DataFrame will have the following columns: **count mean std min 25% 50% 75% max**. Please refer to the assert to have an idea of what is expected. \n",
    "**(2 pts.)**\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df3.copy()\n",
    "df5_rad = df5.groupby(\"RAD\")[\"CRIM\"].describe()\n",
    "df5_rad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert df5.to_dict()=={'count': {1: 192.0, 2: 182.0, 3: 132.0},\n",
    " 'mean': {1: 0.2591065625, 2: 0.5190552747252748, 3: 12.75929090909091},\n",
    " 'std': {1: 0.3799485400326451, 2: 0.7861597586426312, 3: 13.0411694541406},\n",
    " 'min': {1: 0.00632, 2: 0.01311, 3: 2.37857},\n",
    " '25%': {1: 0.045107499999999995, 2: 0.087375, 3: 5.6863075},\n",
    " '50%': {1: 0.094515, 2: 0.17152499999999998, 3: 9.084990000000001},\n",
    " '75%': {1: 0.2744225, 2: 0.5253425, 3: 14.3337},\n",
    " 'max': {1: 2.63548, 2: 4.0974, 3: 88.9762}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titanic Dataset\n",
    "\n",
    "For the following items, we will use the titanic dataset. For more details regarding the dataset, see this link: https://www.kaggle.com/c/titanic/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic = pd.read_csv('titanic.csv')\n",
    "df_titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6.** Let's do some feature engineering on the `Name` column, which has the following format:\n",
    "```<Surname>, <Title> <Name> <Middle Name>```.\n",
    "\n",
    "Your task is to transform the whole text to just the **Surname**. For example, ***Braund*, Mr. Owen Harris** will become ***Braund*** and ***Heikkinen*, Miss. Laina** will become ***Heikkinen***.\n",
    "\n",
    "Hint! Use the built-in `split` function in string data types.\n",
    "\n",
    "**(3 pts.)**\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df_titanic.copy()\n",
    "name = df6[\"Name\"].str.split(\",\", n = 1, expand = True)\n",
    "df6[\"Name\"] = name[0]\n",
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert df6['Name'].tolist()[:10]==['Braund', 'Cumings', 'Heikkinen', 'Futrelle', 'Allen', \n",
    "                                   'Moran', 'McCarthy', 'Palsson', 'Johnson', 'Nasser']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7.** Again, the focus is on column `Name`. Let's assume that the following format holds true for all instances:\n",
    "```<Surname>, <Title> <Name> <Middle Name>```.\n",
    "\n",
    "Your task is to create new columns named **Surname** and **Title** containing the corresponding extracted details. For example, ***Braund*, *Mr.* Owen Harris** will get us ***Braund*** for the surname and ***Mr.*** for the title, and ***Heikkinen*, *Miss.* Laina** will get us ***Heikkinen*** for the surname and ***Miss.*** for the title.\n",
    "\n",
    "Hint! Use the built-in `split` function in string data types.\n",
    "\n",
    "**(3 pts.)**\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = df_titanic.copy()\n",
    "surname = df7[\"Name\"].str.split(\",\", n = 1, expand = True)\n",
    "title = surname[1].str.split(\" \", n = 2, expand = True)\n",
    "df7[\"Surname\"] = surname[0]\n",
    "df7[\"Title\"] = title[1]\n",
    "df7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert df7['Surname'].tolist()[:10]==['Braund', 'Cumings', 'Heikkinen', 'Futrelle', 'Allen', \n",
    "                                      'Moran', 'McCarthy', 'Palsson', 'Johnson', 'Nasser']\n",
    "assert df7['Title'].tolist()[:10]==['Mr.', 'Mrs.', 'Miss.', 'Mrs.', 'Mr.', 'Mr.', 'Mr.', 'Master.', 'Mrs.', 'Mrs.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8.** Drop all entries with null values, and then get the cabin letter from the `Cabin` column by simply retrieving the first letter in the string. Assign that into a new column named `CabinLetter`. Lastly, filter out the male entries.\n",
    "\n",
    "**(4 pts.)**\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8 = df_titanic.copy()\n",
    "#df8_cabin = df8.dropna(subset = [\"Cabin\"])\n",
    "df8_cabin = df8.dropna() #drop if any column is missing\n",
    "df8_cabin[\"CabinLetter\"] = df8_cabin[\"Cabin\"].str[0]\n",
    "df8_female = df8_cabin[df8_cabin[\"Sex\"] == \"female\"]\n",
    "df8_female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8_female.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8_female.head().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert df8.shape==(88, 13) \n",
    "assert df8.head().to_dict()=={'PassengerId': {1: 2, 3: 4, 10: 11, 11: 12, 52: 53},\n",
    " 'Survived': {1: 1, 3: 1, 10: 1, 11: 1, 52: 1},\n",
    " 'Pclass': {1: 1, 3: 1, 10: 3, 11: 1, 52: 1},\n",
    " 'Name': {1: 'Cumings, Mrs. John Bradley (Florence Briggs Thayer)',\n",
    "  3: 'Futrelle, Mrs. Jacques Heath (Lily May Peel)',\n",
    "  10: 'Sandstrom, Miss. Marguerite Rut',\n",
    "  11: 'Bonnell, Miss. Elizabeth',\n",
    "  52: 'Harper, Mrs. Henry Sleeper (Myna Haxtun)'},\n",
    " 'Sex': {1: 'female', 3: 'female', 10: 'female', 11: 'female', 52: 'female'},\n",
    " 'Age': {1: 38.0, 3: 35.0, 10: 4.0, 11: 58.0, 52: 49.0},\n",
    " 'SibSp': {1: 1, 3: 1, 10: 1, 11: 0, 52: 1},\n",
    " 'Parch': {1: 0, 3: 0, 10: 1, 11: 0, 52: 0},\n",
    " 'Ticket': {1: 'PC 17599',\n",
    "  3: '113803',\n",
    "  10: 'PP 9549',\n",
    "  11: '113783',\n",
    "  52: 'PC 17572'},\n",
    " 'Fare': {1: 71.2833, 3: 53.1, 10: 16.7, 11: 26.55, 52: 76.7292},\n",
    " 'Cabin': {1: 'C85', 3: 'C123', 10: 'G6', 11: 'C103', 52: 'D33'},\n",
    " 'Embarked': {1: 'C', 3: 'S', 10: 'S', 11: 'S', 52: 'C'},\n",
    " 'CabinLetter': {1: 'C', 3: 'C', 10: 'G', 11: 'C', 52: 'D'}}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
